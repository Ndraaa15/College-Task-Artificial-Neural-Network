{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gede Indra Adi Brata - 225150200111006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "  [1, 1, 1, 1], \n",
    "  [-1, 1, -1, -1], \n",
    "  [1, 1, 1, -1], \n",
    "  [1, -1, -1, 1]\n",
    "]\n",
    "B = [1, 1, 1, 1]\n",
    "T = [1, 1, -1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_bipolar(y_in, th=0):\n",
    "  if y_in > th:\n",
    "    return 1\n",
    "  elif y_in < th:\n",
    "    return -1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(weight, x, bias):\n",
    "  return np.dot(weight, x) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_fit_v1(train, target, epoch, learning_rate):\n",
    "  w = np.zeros(len(train[0]))\n",
    "  b = 1\n",
    "  \n",
    "  for _ in range(epoch):\n",
    "    for r, row in enumerate(train):\n",
    "      y_in = weighted_sum(w, row, b)\n",
    "      y = step_bipolar(y_in)\n",
    "      w = [w[i] + learning_rate * (target[r] - y) * row[i] for i in range(len(row))]\n",
    "      b = b + learning_rate * (target[r] - y)\n",
    "  \n",
    "  return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_fit_v2(train, target, epoch, learning_rate):\n",
    "  w = np.zeros(len(train[0]))\n",
    "  b = 1\n",
    "  \n",
    "  for _ in range(epoch):\n",
    "    for r, row in enumerate(train):\n",
    "      y_in = weighted_sum(w, row, b)\n",
    "      y = step_bipolar(y_in)\n",
    "      if y != target[r]:\n",
    "        w = [w[i] + learning_rate * target[r] * row[i] for i in range(len(row))]\n",
    "        b = b + learning_rate * target[r]\n",
    "\n",
    "  \n",
    "  return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The value of weight using perceptron_fit_v1 is : [-4.0, 4.0, 0.0, 4.0]\n",
      " The value of bias using perceptron_fit_v1 is : 1\n"
     ]
    }
   ],
   "source": [
    "weight_v1, bias_v1 = perceptron_fit_v1(X, T, 10, 1)\n",
    "print(f\" The value of weight using perceptron_fit_v1 is : {weight_v1}\")\n",
    "print(f\" The value of bias using perceptron_fit_v1 is : {bias_v1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The value of weight using perceptron_fit_v2 is : [-2.0, 2.0, 0.0, 2.0]\n",
      " The value of bias using perceptron_fit_v2 is : 1\n"
     ]
    }
   ],
   "source": [
    "weight_v2, bias_v2 = perceptron_fit_v2(X, T, 10, 1)\n",
    "print(f\" The value of weight using perceptron_fit_v2 is : {weight_v2}\")\n",
    "print(f\" The value of bias using perceptron_fit_v2 is : {bias_v2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakukan prediksi dengan data berikut pada masing masing rumus weight update perceptron dan tampilkan hasilnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [\n",
    "  [1, -1, 1, 1], \n",
    "  [-1, -1, -1, -1],\n",
    "]\n",
    "bias = [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of perceptron for row [1, -1, 1, 1] is : -1\n",
      "The output of perceptron for row [-1, -1, -1, -1] is : -1\n"
     ]
    }
   ],
   "source": [
    "for r, row in enumerate(X_test):\n",
    "  y_in = weighted_sum(weight_v1, row, bias[r])\n",
    "  y = step_bipolar(y_in)\n",
    "  print(f\"The output of perceptron for row {row} is : {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of perceptron for row [1, -1, 1, 1] is : -1\n",
      "The output of perceptron for row [-1, -1, -1, -1] is : -1\n"
     ]
    }
   ],
   "source": [
    "for r, row in enumerate(X_test):\n",
    "  y_in = weighted_sum(weight_v2, row, bias[r])\n",
    "  y = step_bipolar(y_in)\n",
    "  print(f\"The output of perceptron for row {row} is : {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apakah terdapat kekurangan pada rumus weight pertama dan kedua? Jika ada jelaskan\n",
    "\n",
    "Pada kedua versi fungsi perceptron_fit_v1 dan perceptron_fit_v2, terdapat perbedaan dalam cara memperbarui bobot (weights) dan bias, yang bisa mempengaruhi performa pembelajaran perceptron.\n",
    "\n",
    "#### perceptron_fit_v1:\n",
    "- Kekurangan:\n",
    "  - Pada versi ini, pembaruan bobot dan bias dilakukan setiap kali terjadi kesalahan prediksi (target[r] - y). Ini baik untuk pembelajaran batch, tetapi dalam pembelajaran online, ada risiko pembaruan yang terlalu sering.\n",
    "  - Rumus (target[r] - y) memperhitungkan kesalahan (error), yang mungkin menyebabkan osilasi dalam pembaruan bobot jika terlalu sering. Ini juga bisa membuat proses konvergensi menjadi lebih lambat.\n",
    "  - v1 selalu melakukan update pada setiap iterasi.\n",
    "  - v1 melakukan lebih banyak perhitungan karena selalu mengupdate.\n",
    "\n",
    "\n",
    "#### perceptron_fit_v2:\n",
    "- Kekurangan:\n",
    "  - Di sini, bobot hanya diperbarui ketika prediksi salah (y != target[r]), sehingga pembaruan lebih terarah pada koreksi kesalahan.\n",
    "  - Tidak ada perhitungan kesalahan (t - y) dalam rumus pembaruan, yang membuat proses pembaruan bisa lebih stabil dibandingkan v1.\n",
    "  - Namun, versi ini mungkin lebih cepat dalam beberapa kasus karena menghindari pembaruan yang tidak perlu, tetapi ada kemungkinan ia bisa gagal menangkap margin yang cukup besar antara kelas-kelas jika terdapat noise pada data.\n",
    "  - v2 lebih efisien karena hanya mengupdate saat diperlukan.\n",
    "\n",
    "Kesimpulan:\n",
    "- v1 lebih cocok jika Anda ingin lebih mempertimbangkan besarnya kesalahan, namun bisa kurang stabil.\n",
    "- v2 lebih sederhana dan lebih stabil, tetapi mungkin kurang fleksibel dalam menangani dataset dengan noise atau margin yang kecil antara kelas-kelas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jika anda diminta untuk melatih arsitektur perceptron menggunakan 1 juta data dan memprediksi 500 ribu data, rumus weight update mana yang akan anda pilih dan kenapa?\n",
    "\n",
    "Apabila diminta untuk melatih jaringan perceptron dengan 1 juta data dan memprediksi 500 ribu data, maka saya akan menggunakan rumus weight\n",
    "\n",
    "``` if (y_out != target) w' = w + alpha * target * x ```\n",
    "\n",
    "karena dengan rumus ini hanya melakukan kalkulasi apabila suatu kondisi terpenuhi, yaitu y_out != target, Hal ini membuat arsitektur perceptron dengan rumus weight ini menjadi lebih efektif."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
