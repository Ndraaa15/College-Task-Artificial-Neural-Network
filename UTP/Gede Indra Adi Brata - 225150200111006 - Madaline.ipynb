{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bjtQIOJFQi9"
   },
   "source": [
    "# MultiVariable MADALINE Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KvtIZk8EMQ_"
   },
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "159rFKI7EQ6j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyv0lAzHNonP"
   },
   "source": [
    "## MADALINE Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "oj9-qpcRFUEj"
   },
   "outputs": [],
   "source": [
    "def majority_vote(z):\n",
    "    \"\"\"Compute the majority vote of the hidden layer outputs.\"\"\"\n",
    "    return 1 if np.sum(z) >= 0 else -1\n",
    "\n",
    "def aktivasi(x):\n",
    "    \"\"\"Step function to determine the binary output (-1 or 1).\"\"\"\n",
    "    return 1 if x >= 0 else -1\n",
    "\n",
    "def train_madaline(train_data, train_target, input_neuron: int, hidden_neuron: int, alpha: float, max_epoch: int, verbose: bool=False):\n",
    "    train_data = np.array(train_data)\n",
    "    train_target = np.array(train_target)\n",
    "    w = np.random.random((input_neuron, hidden_neuron))  # Initialize weights for ADALINE units\n",
    "    b = np.random.random(hidden_neuron)       # Bias for hidden layer ADALINE units\n",
    "    b = np.append(b, 0.5)                     # Bias for the output unit\n",
    "    v = np.array([1] * hidden_neuron)         # Initialize output layer weights (all 1 for Madaline)\n",
    "    epoch = 0\n",
    "    weight_updated = True\n",
    "\n",
    "    v_aktivasi = np.vectorize(aktivasi)\n",
    "\n",
    "    while weight_updated and epoch < max_epoch:\n",
    "        weight_updated = False\n",
    "        for data, target in zip(train_data, train_target):\n",
    "            # Calculate hidden layer outputs (z_in and z)\n",
    "            z_in = np.dot(data, w) + b[:-1]\n",
    "            z = v_aktivasi(z_in)  # Activation function on hidden layer outputs\n",
    "\n",
    "            # Majority vote for output layer\n",
    "            y = majority_vote(z)\n",
    "\n",
    "            # If the majority vote output doesn't match the target, apply MR1\n",
    "            if y != target:\n",
    "                weight_updated = True\n",
    "                # We need to flip some of the ADALINE units to correct the error\n",
    "                if target == 1:\n",
    "                    # Flip the minimum number of units from -1 to 1 (i.e., from negative to positive)\n",
    "                    flip_candidates = np.where(z == -1)[0]\n",
    "                else:\n",
    "                    # Flip the minimum number of units from +1 to -1 (i.e., from positive to negative)\n",
    "                    flip_candidates = np.where(z == 1)[0]\n",
    "\n",
    "                # Select the units closest to flipping (minimal disturbance principle)\n",
    "                min_indices = np.argsort(np.abs(z_in[flip_candidates]))  # Sort by how close to flipping\n",
    "                num_to_flip = int(np.ceil(len(flip_candidates) / 2))  # Determine how many to flip (minimal number to flip majority)\n",
    "\n",
    "                for i in range(num_to_flip):\n",
    "                    selected_unit = flip_candidates[min_indices[i]]\n",
    "\n",
    "                    if target == 1:\n",
    "                        # Make the selected unit flip from -1 to 1\n",
    "                        b[selected_unit] = b[selected_unit] + alpha * (1 - z_in[selected_unit])\n",
    "                        w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
    "                    elif target == -1:\n",
    "                        # Make the selected unit flip from 1 to -1\n",
    "                        b[selected_unit] = b[selected_unit] + alpha * (-1 - z_in[selected_unit])\n",
    "                        w[:, selected_unit] = w[:, selected_unit] + alpha * (-1 - z_in[selected_unit]) * data\n",
    "\n",
    "        if verbose:\n",
    "          print(\"Weights after epoch\", epoch + 1, \":\", w)\n",
    "          print(\"Biases after epoch\", epoch + 1, \":\", b)\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    return w, v, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Hy7CE3-NGG1Z"
   },
   "outputs": [],
   "source": [
    "def test(w,v,b,test_data):\n",
    "  v_aktivasi = np.vectorize(aktivasi)\n",
    "  z_in = np.dot(test_data, w)\n",
    "  z_in = z_in + b[:-1]\n",
    "  z = v_aktivasi(z_in)\n",
    "  y_in = np.dot(z, v) + b[-1]\n",
    "  y = v_aktivasi(y_in)\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "T5dvF_Lw_sL6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after epoch 1 : [[0.78311343 0.02556099]\n",
      " [0.86933179 0.31503566]]\n",
      "Biases after epoch 1 : [ 0.93124343 -0.33010988  0.5       ]\n",
      "Weights after epoch 2 : [[ 0.78311343 -0.2270607 ]\n",
      " [ 0.86933179  0.06241397]]\n",
      "Biases after epoch 2 : [ 0.93124343 -0.58273157  0.5       ]\n",
      "Weights after epoch 3 : [[ 0.29530458 -0.2270607 ]\n",
      " [ 0.42666672  0.06241397]]\n",
      "Biases after epoch 3 : [ 0.1526565  -0.58273157  0.5       ]\n",
      "Weights after epoch 4 : [[ 0.50378398 -0.55037493]\n",
      " [-0.08853518  0.38572819]]\n",
      "Biases after epoch 4 : [-0.2694555  -0.25941735  0.5       ]\n",
      "Weights after epoch 5 : [[ 0.21733565 -0.55037493]\n",
      " [-0.3749835   0.38572819]]\n",
      "Biases after epoch 5 : [-0.55590383 -0.25941735  0.5       ]\n",
      "Weights after epoch 6 : [[ 0.21733565 -0.55037493]\n",
      " [-0.3749835   0.38572819]]\n",
      "Biases after epoch 6 : [-0.55590383 -0.25941735  0.5       ]\n",
      "Output: [-1  1  1 -1]\n",
      "Target: [-1  1  1 -1]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "data = np.array([[1,1],[1,-1],[-1,1],[-1,-1]])\n",
    "target = np.array([-1, 1, 1,-1])\n",
    "(w,v,b) = train_madaline(data,target,input_neuron=2, hidden_neuron=2, alpha=0.25, max_epoch=10, verbose=True)\n",
    "output = test(w,v,b,data)\n",
    "accuracy = accuracy_score(output, target)\n",
    "\n",
    "print('Output:', output)\n",
    "print('Target:', target)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vB9yEP1Dgjg"
   },
   "source": [
    "# MADALINE Multi Variable (Breast Cancer Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktuBZUaHD48o"
   },
   "source": [
    "## Load dataset Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "MTZqov3RDBpB"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X_cancer, y_cancer = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Mengubah label 0 menjadi -1\n",
    "y_cancer = np.where(y_cancer == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Z2wQsXihE8R_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcnIHYjDKO2E"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFaSdHgTZYiv"
   },
   "source": [
    "Standarisasi data menggunakan StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "slrZqyxIKQzn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.07200079, -0.6584246 , -1.0880801 , ..., -1.35052668,\n",
       "        -0.35265805, -0.54138003],\n",
       "       [ 1.74874285,  0.06650173,  1.75115682, ...,  1.54991557,\n",
       "         0.19107787, -0.1737386 ],\n",
       "       [-0.97473376, -0.93112416, -0.99770871, ..., -1.70744192,\n",
       "        -0.307734  , -1.21303263],\n",
       "       ...,\n",
       "       [ 0.39844772,  1.06867262,  0.50751384, ...,  1.53492543,\n",
       "         0.16164487,  1.23754763],\n",
       "       [ 0.85331409, -0.0380331 ,  0.9054796 , ...,  2.10455077,\n",
       "         0.31035897,  0.36249578],\n",
       "       [-0.91179628, -0.82431683, -0.87666079, ..., -0.51332734,\n",
       "        -0.50756857,  1.30824791]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_cancer = StandardScaler()\n",
    "X_train_cancer = std_cancer.fit_transform(X_train_cancer)\n",
    "X_test_cancer = std_cancer.transform(X_test_cancer)\n",
    "\n",
    "X_train_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA5AFdUDNAf-"
   },
   "source": [
    "## Pemodelan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "can6TIpKGVO4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: invalid value encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:56: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (-1 - z_in[selected_unit]) * data\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:56: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (-1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:56: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (-1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:56: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (-1 - z_in[selected_unit]) * data\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: invalid value encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:56: RuntimeWarning: overflow encountered in multiply\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (-1 - z_in[selected_unit]) * data\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:52: RuntimeWarning: invalid value encountered in add\n",
      "  w[:, selected_unit] = w[:, selected_unit] + alpha * (1 - z_in[selected_unit]) * data\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: invalid value encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "C:\\Users\\indra\\AppData\\Local\\Temp\\ipykernel_17656\\1736094767.py:25: RuntimeWarning: overflow encountered in add\n",
      "  z_in = np.dot(data, w) + b[:-1]\n",
      "c:\\Users\\indra\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2455: RuntimeWarning: invalid value encountered in aktivasi (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_neuron': 5, 'alpha': 0.05, 'max_epoch': 100, 'accuracy': 0.9824561403508771}\n"
     ]
    }
   ],
   "source": [
    "hidden_neuron =  [5, 10, 15]\n",
    "alpha = [0.05, 0.1, 0.5]\n",
    "max_epoch = [100, 500, 1000]\n",
    "\n",
    "acc = 0\n",
    "best_params = {}\n",
    "\n",
    "for h in hidden_neuron:\n",
    "    for a in alpha:\n",
    "        for e in max_epoch:\n",
    "            w, v, b = train_madaline(X_train_cancer, y_train_cancer, input_neuron=len(X_train_cancer[0]), hidden_neuron=h, alpha=a, max_epoch=e)\n",
    "            y_pred = test(w, v, b, X_test_cancer)\n",
    "            current_acc = accuracy_score(y_test_cancer, y_pred)\n",
    "            \n",
    "            if acc < current_acc:\n",
    "                acc = current_acc\n",
    "                best_params['hidden_neuron'] = h\n",
    "                best_params['alpha'] = a\n",
    "                best_params['max_epoch'] = e\n",
    "                best_params['accuracy'] = acc\n",
    "                \n",
    "                \n",
    "            \n",
    "print(best_params)\n",
    "\n",
    "(w, v, b) = train_madaline(X_train_cancer, y_test_cancer,input_neuron=len(X_train_cancer[0]), hidden_neuron=best_params['hidden_neuron'], alpha=best_params['alpha'], max_epoch=best_params['max_epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best params\n",
    "\n",
    "{'hidden_neuron': 5, 'alpha': 0.05, 'max_epoch': 100, 'accuracy': 0.9824561403508771}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_A7bj378_K1"
   },
   "source": [
    "## Pengujian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ATITpyIYHXxM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.63      0.63        41\n",
      "           1       0.79      0.78      0.79        73\n",
      "\n",
      "    accuracy                           0.73       114\n",
      "   macro avg       0.71      0.71      0.71       114\n",
      "weighted avg       0.73      0.73      0.73       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_cancer = test(w,v,b, X_test_cancer)\n",
    "print(classification_report(output_cancer, y_test_cancer, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "x7BW-hojIM0V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25cf6fc3b00>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(output_cancer, y_test_cancer)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P29q5u6MGNi"
   },
   "source": [
    "# MADALINE Multi Variable & Multi Kelas (Wine Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjMTg7mYNxmJ"
   },
   "source": [
    "## Load Dataset Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "PNetNc7BNwsz"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_wine, y_wine = load_wine(return_X_y=True)\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42, stratify=y_wine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et7D1DxBP4aM"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "g92IRSXFP4aN"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_wine = StandardScaler()\n",
    "X_train_wine = std_wine.fit_transform(X_train_wine)\n",
    "X_test_wine = std_wine.transform(X_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "mFsi5YhkTbA1"
   },
   "outputs": [],
   "source": [
    "data_latih = pd.DataFrame(X_train_wine)\n",
    "data_latih['target'] = y_train_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX78SUecQJRy"
   },
   "source": [
    "## Membuat One-vs-Rest Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1jjqJJLaEtD"
   },
   "source": [
    "Metode one-vs-rest memerlukan tiga jenis data latih yang diperlukan untuk melatih\n",
    "tiga MADALINE yang berbeda pada dataset Wine. Fungsi buat_trainingset digunakan untuk\n",
    "membentuk tiga dataset tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "H-eQGBuhQkcY"
   },
   "outputs": [],
   "source": [
    "def membuat_trainingset(dataset):\n",
    "  trainingset = {}\n",
    "  kolom_kelas = dataset.columns[-1]\n",
    "  list_kelas = dataset[kolom_kelas].unique()\n",
    "  for kelas in list_kelas:\n",
    "    data_temp = dataset.copy(deep=True)\n",
    "    data_temp[kolom_kelas] = data_temp[kolom_kelas].map({kelas:1})\n",
    "    data_temp[kolom_kelas] = data_temp[kolom_kelas].fillna(-1)\n",
    "    trainingset[kelas]=data_temp\n",
    "  return trainingset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ytpWVei2TxoU"
   },
   "outputs": [],
   "source": [
    "trainingset = membuat_trainingset(data_latih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "5yF6j1QybA_R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 2, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "K8Imt7OTaoLe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385801</td>\n",
       "      <td>-0.637871</td>\n",
       "      <td>1.776668</td>\n",
       "      <td>-1.224532</td>\n",
       "      <td>0.696430</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.732292</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-0.415783</td>\n",
       "      <td>-0.167467</td>\n",
       "      <td>0.624378</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.467725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.948519</td>\n",
       "      <td>-0.765445</td>\n",
       "      <td>1.253174</td>\n",
       "      <td>0.853284</td>\n",
       "      <td>0.091785</td>\n",
       "      <td>1.172795</td>\n",
       "      <td>1.333181</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>1.349742</td>\n",
       "      <td>0.305303</td>\n",
       "      <td>1.067155</td>\n",
       "      <td>0.151048</td>\n",
       "      <td>1.815768</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523354</td>\n",
       "      <td>-0.519409</td>\n",
       "      <td>0.954034</td>\n",
       "      <td>-1.046433</td>\n",
       "      <td>-0.445678</td>\n",
       "      <td>0.930572</td>\n",
       "      <td>1.006382</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-0.260002</td>\n",
       "      <td>-0.081509</td>\n",
       "      <td>-0.128343</td>\n",
       "      <td>0.893172</td>\n",
       "      <td>1.516203</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973529</td>\n",
       "      <td>-0.555859</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>-1.076116</td>\n",
       "      <td>-0.714409</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.816627</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>0.363125</td>\n",
       "      <td>0.262324</td>\n",
       "      <td>0.890044</td>\n",
       "      <td>0.427526</td>\n",
       "      <td>1.932265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435820</td>\n",
       "      <td>0.820120</td>\n",
       "      <td>0.056615</td>\n",
       "      <td>0.556453</td>\n",
       "      <td>-0.512860</td>\n",
       "      <td>-0.555068</td>\n",
       "      <td>-1.291756</td>\n",
       "      <td>0.756449</td>\n",
       "      <td>-0.606183</td>\n",
       "      <td>1.474335</td>\n",
       "      <td>-1.766619</td>\n",
       "      <td>-1.435059</td>\n",
       "      <td>-0.297831</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.685917</td>\n",
       "      <td>0.756333</td>\n",
       "      <td>1.327959</td>\n",
       "      <td>1.150115</td>\n",
       "      <td>-0.176946</td>\n",
       "      <td>-1.168702</td>\n",
       "      <td>-1.544762</td>\n",
       "      <td>1.177357</td>\n",
       "      <td>-1.817818</td>\n",
       "      <td>-0.274915</td>\n",
       "      <td>-0.261176</td>\n",
       "      <td>-0.794796</td>\n",
       "      <td>-0.730536</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-1.652489</td>\n",
       "      <td>-0.610534</td>\n",
       "      <td>0.954034</td>\n",
       "      <td>1.892192</td>\n",
       "      <td>-0.781592</td>\n",
       "      <td>-0.571216</td>\n",
       "      <td>-0.395693</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>-0.450402</td>\n",
       "      <td>-1.027050</td>\n",
       "      <td>1.819877</td>\n",
       "      <td>0.878620</td>\n",
       "      <td>-0.590739</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.673412</td>\n",
       "      <td>-0.492072</td>\n",
       "      <td>1.066212</td>\n",
       "      <td>-0.185624</td>\n",
       "      <td>0.696430</td>\n",
       "      <td>0.123159</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>-0.104220</td>\n",
       "      <td>-0.339384</td>\n",
       "      <td>0.668656</td>\n",
       "      <td>0.383871</td>\n",
       "      <td>1.183353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.014354</td>\n",
       "      <td>1.011481</td>\n",
       "      <td>-0.055562</td>\n",
       "      <td>-0.334039</td>\n",
       "      <td>0.427699</td>\n",
       "      <td>-1.427074</td>\n",
       "      <td>-1.355008</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>-1.142765</td>\n",
       "      <td>0.124791</td>\n",
       "      <td>-1.191008</td>\n",
       "      <td>-1.245891</td>\n",
       "      <td>-0.214618</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.114393</td>\n",
       "      <td>0.592309</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.111207</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>-1.572408</td>\n",
       "      <td>-0.806828</td>\n",
       "      <td>-1.011365</td>\n",
       "      <td>-1.333164</td>\n",
       "      <td>0.176366</td>\n",
       "      <td>-0.925342</td>\n",
       "      <td>-1.726088</td>\n",
       "      <td>-0.697251</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.385801 -0.637871  1.776668 -1.224532  0.696430  0.526865  0.732292   \n",
       "1    0.948519 -0.765445  1.253174  0.853284  0.091785  1.172795  1.333181   \n",
       "2    0.523354 -0.519409  0.954034 -1.046433 -0.445678  0.930572  1.006382   \n",
       "3    0.973529 -0.555859  0.168793 -1.076116 -0.714409  0.526865  0.816627   \n",
       "4    0.435820  0.820120  0.056615  0.556453 -0.512860 -0.555068 -1.291756   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "137  0.685917  0.756333  1.327959  1.150115 -0.176946 -1.168702 -1.544762   \n",
       "138 -1.652489 -0.610534  0.954034  1.892192 -0.781592 -0.571216 -0.395693   \n",
       "139  0.673412 -0.492072  1.066212 -0.185624  0.696430  0.123159  0.574163   \n",
       "140 -0.014354  1.011481 -0.055562 -0.334039  0.427699 -1.427074 -1.355008   \n",
       "141 -0.114393  0.592309  0.131400  0.111207  0.293333 -1.572408 -0.806828   \n",
       "\n",
       "            7         8         9        10        11        12  target  \n",
       "0   -0.169549 -0.415783 -0.167467  0.624378  0.252908  0.467725     1.0  \n",
       "1   -0.590457  1.349742  0.305303  1.067155  0.151048  1.815768     1.0  \n",
       "2   -0.169549 -0.260002 -0.081509 -0.128343  0.893172  1.516203     1.0  \n",
       "3   -0.590457  0.363125  0.262324  0.890044  0.427526  1.932265     1.0  \n",
       "4    0.756449 -0.606183  1.474335 -1.766619 -1.435059 -0.297831    -1.0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "137  1.177357 -1.817818 -0.274915 -0.261176 -0.794796 -0.730536    -1.0  \n",
       "138  0.335541 -0.450402 -1.027050  1.819877  0.878620 -0.590739    -1.0  \n",
       "139 -0.590457 -0.104220 -0.339384  0.668656  0.383871  1.183353     1.0  \n",
       "140  0.335541 -1.142765  0.124791 -1.191008 -1.245891 -0.214618    -1.0  \n",
       "141 -1.011365 -1.333164  0.176366 -0.925342 -1.726088 -0.697251    -1.0  \n",
       "\n",
       "[142 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set kelas 0\n",
    "trainingset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "NRcQZsNra6p4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385801</td>\n",
       "      <td>-0.637871</td>\n",
       "      <td>1.776668</td>\n",
       "      <td>-1.224532</td>\n",
       "      <td>0.696430</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.732292</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-0.415783</td>\n",
       "      <td>-0.167467</td>\n",
       "      <td>0.624378</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.467725</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.948519</td>\n",
       "      <td>-0.765445</td>\n",
       "      <td>1.253174</td>\n",
       "      <td>0.853284</td>\n",
       "      <td>0.091785</td>\n",
       "      <td>1.172795</td>\n",
       "      <td>1.333181</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>1.349742</td>\n",
       "      <td>0.305303</td>\n",
       "      <td>1.067155</td>\n",
       "      <td>0.151048</td>\n",
       "      <td>1.815768</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523354</td>\n",
       "      <td>-0.519409</td>\n",
       "      <td>0.954034</td>\n",
       "      <td>-1.046433</td>\n",
       "      <td>-0.445678</td>\n",
       "      <td>0.930572</td>\n",
       "      <td>1.006382</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-0.260002</td>\n",
       "      <td>-0.081509</td>\n",
       "      <td>-0.128343</td>\n",
       "      <td>0.893172</td>\n",
       "      <td>1.516203</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973529</td>\n",
       "      <td>-0.555859</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>-1.076116</td>\n",
       "      <td>-0.714409</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.816627</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>0.363125</td>\n",
       "      <td>0.262324</td>\n",
       "      <td>0.890044</td>\n",
       "      <td>0.427526</td>\n",
       "      <td>1.932265</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435820</td>\n",
       "      <td>0.820120</td>\n",
       "      <td>0.056615</td>\n",
       "      <td>0.556453</td>\n",
       "      <td>-0.512860</td>\n",
       "      <td>-0.555068</td>\n",
       "      <td>-1.291756</td>\n",
       "      <td>0.756449</td>\n",
       "      <td>-0.606183</td>\n",
       "      <td>1.474335</td>\n",
       "      <td>-1.766619</td>\n",
       "      <td>-1.435059</td>\n",
       "      <td>-0.297831</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.685917</td>\n",
       "      <td>0.756333</td>\n",
       "      <td>1.327959</td>\n",
       "      <td>1.150115</td>\n",
       "      <td>-0.176946</td>\n",
       "      <td>-1.168702</td>\n",
       "      <td>-1.544762</td>\n",
       "      <td>1.177357</td>\n",
       "      <td>-1.817818</td>\n",
       "      <td>-0.274915</td>\n",
       "      <td>-0.261176</td>\n",
       "      <td>-0.794796</td>\n",
       "      <td>-0.730536</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-1.652489</td>\n",
       "      <td>-0.610534</td>\n",
       "      <td>0.954034</td>\n",
       "      <td>1.892192</td>\n",
       "      <td>-0.781592</td>\n",
       "      <td>-0.571216</td>\n",
       "      <td>-0.395693</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>-0.450402</td>\n",
       "      <td>-1.027050</td>\n",
       "      <td>1.819877</td>\n",
       "      <td>0.878620</td>\n",
       "      <td>-0.590739</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.673412</td>\n",
       "      <td>-0.492072</td>\n",
       "      <td>1.066212</td>\n",
       "      <td>-0.185624</td>\n",
       "      <td>0.696430</td>\n",
       "      <td>0.123159</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>-0.104220</td>\n",
       "      <td>-0.339384</td>\n",
       "      <td>0.668656</td>\n",
       "      <td>0.383871</td>\n",
       "      <td>1.183353</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.014354</td>\n",
       "      <td>1.011481</td>\n",
       "      <td>-0.055562</td>\n",
       "      <td>-0.334039</td>\n",
       "      <td>0.427699</td>\n",
       "      <td>-1.427074</td>\n",
       "      <td>-1.355008</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>-1.142765</td>\n",
       "      <td>0.124791</td>\n",
       "      <td>-1.191008</td>\n",
       "      <td>-1.245891</td>\n",
       "      <td>-0.214618</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.114393</td>\n",
       "      <td>0.592309</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.111207</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>-1.572408</td>\n",
       "      <td>-0.806828</td>\n",
       "      <td>-1.011365</td>\n",
       "      <td>-1.333164</td>\n",
       "      <td>0.176366</td>\n",
       "      <td>-0.925342</td>\n",
       "      <td>-1.726088</td>\n",
       "      <td>-0.697251</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.385801 -0.637871  1.776668 -1.224532  0.696430  0.526865  0.732292   \n",
       "1    0.948519 -0.765445  1.253174  0.853284  0.091785  1.172795  1.333181   \n",
       "2    0.523354 -0.519409  0.954034 -1.046433 -0.445678  0.930572  1.006382   \n",
       "3    0.973529 -0.555859  0.168793 -1.076116 -0.714409  0.526865  0.816627   \n",
       "4    0.435820  0.820120  0.056615  0.556453 -0.512860 -0.555068 -1.291756   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "137  0.685917  0.756333  1.327959  1.150115 -0.176946 -1.168702 -1.544762   \n",
       "138 -1.652489 -0.610534  0.954034  1.892192 -0.781592 -0.571216 -0.395693   \n",
       "139  0.673412 -0.492072  1.066212 -0.185624  0.696430  0.123159  0.574163   \n",
       "140 -0.014354  1.011481 -0.055562 -0.334039  0.427699 -1.427074 -1.355008   \n",
       "141 -0.114393  0.592309  0.131400  0.111207  0.293333 -1.572408 -0.806828   \n",
       "\n",
       "            7         8         9        10        11        12  target  \n",
       "0   -0.169549 -0.415783 -0.167467  0.624378  0.252908  0.467725    -1.0  \n",
       "1   -0.590457  1.349742  0.305303  1.067155  0.151048  1.815768    -1.0  \n",
       "2   -0.169549 -0.260002 -0.081509 -0.128343  0.893172  1.516203    -1.0  \n",
       "3   -0.590457  0.363125  0.262324  0.890044  0.427526  1.932265    -1.0  \n",
       "4    0.756449 -0.606183  1.474335 -1.766619 -1.435059 -0.297831    -1.0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "137  1.177357 -1.817818 -0.274915 -0.261176 -0.794796 -0.730536    -1.0  \n",
       "138  0.335541 -0.450402 -1.027050  1.819877  0.878620 -0.590739     1.0  \n",
       "139 -0.590457 -0.104220 -0.339384  0.668656  0.383871  1.183353    -1.0  \n",
       "140  0.335541 -1.142765  0.124791 -1.191008 -1.245891 -0.214618    -1.0  \n",
       "141 -1.011365 -1.333164  0.176366 -0.925342 -1.726088 -0.697251    -1.0  \n",
       "\n",
       "[142 rows x 14 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set kelas 1\n",
    "trainingset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "f0R3TdO4a9g2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.385801</td>\n",
       "      <td>-0.637871</td>\n",
       "      <td>1.776668</td>\n",
       "      <td>-1.224532</td>\n",
       "      <td>0.696430</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.732292</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-0.415783</td>\n",
       "      <td>-0.167467</td>\n",
       "      <td>0.624378</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.467725</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.948519</td>\n",
       "      <td>-0.765445</td>\n",
       "      <td>1.253174</td>\n",
       "      <td>0.853284</td>\n",
       "      <td>0.091785</td>\n",
       "      <td>1.172795</td>\n",
       "      <td>1.333181</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>1.349742</td>\n",
       "      <td>0.305303</td>\n",
       "      <td>1.067155</td>\n",
       "      <td>0.151048</td>\n",
       "      <td>1.815768</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.523354</td>\n",
       "      <td>-0.519409</td>\n",
       "      <td>0.954034</td>\n",
       "      <td>-1.046433</td>\n",
       "      <td>-0.445678</td>\n",
       "      <td>0.930572</td>\n",
       "      <td>1.006382</td>\n",
       "      <td>-0.169549</td>\n",
       "      <td>-0.260002</td>\n",
       "      <td>-0.081509</td>\n",
       "      <td>-0.128343</td>\n",
       "      <td>0.893172</td>\n",
       "      <td>1.516203</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973529</td>\n",
       "      <td>-0.555859</td>\n",
       "      <td>0.168793</td>\n",
       "      <td>-1.076116</td>\n",
       "      <td>-0.714409</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.816627</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>0.363125</td>\n",
       "      <td>0.262324</td>\n",
       "      <td>0.890044</td>\n",
       "      <td>0.427526</td>\n",
       "      <td>1.932265</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435820</td>\n",
       "      <td>0.820120</td>\n",
       "      <td>0.056615</td>\n",
       "      <td>0.556453</td>\n",
       "      <td>-0.512860</td>\n",
       "      <td>-0.555068</td>\n",
       "      <td>-1.291756</td>\n",
       "      <td>0.756449</td>\n",
       "      <td>-0.606183</td>\n",
       "      <td>1.474335</td>\n",
       "      <td>-1.766619</td>\n",
       "      <td>-1.435059</td>\n",
       "      <td>-0.297831</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.685917</td>\n",
       "      <td>0.756333</td>\n",
       "      <td>1.327959</td>\n",
       "      <td>1.150115</td>\n",
       "      <td>-0.176946</td>\n",
       "      <td>-1.168702</td>\n",
       "      <td>-1.544762</td>\n",
       "      <td>1.177357</td>\n",
       "      <td>-1.817818</td>\n",
       "      <td>-0.274915</td>\n",
       "      <td>-0.261176</td>\n",
       "      <td>-0.794796</td>\n",
       "      <td>-0.730536</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-1.652489</td>\n",
       "      <td>-0.610534</td>\n",
       "      <td>0.954034</td>\n",
       "      <td>1.892192</td>\n",
       "      <td>-0.781592</td>\n",
       "      <td>-0.571216</td>\n",
       "      <td>-0.395693</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>-0.450402</td>\n",
       "      <td>-1.027050</td>\n",
       "      <td>1.819877</td>\n",
       "      <td>0.878620</td>\n",
       "      <td>-0.590739</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.673412</td>\n",
       "      <td>-0.492072</td>\n",
       "      <td>1.066212</td>\n",
       "      <td>-0.185624</td>\n",
       "      <td>0.696430</td>\n",
       "      <td>0.123159</td>\n",
       "      <td>0.574163</td>\n",
       "      <td>-0.590457</td>\n",
       "      <td>-0.104220</td>\n",
       "      <td>-0.339384</td>\n",
       "      <td>0.668656</td>\n",
       "      <td>0.383871</td>\n",
       "      <td>1.183353</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.014354</td>\n",
       "      <td>1.011481</td>\n",
       "      <td>-0.055562</td>\n",
       "      <td>-0.334039</td>\n",
       "      <td>0.427699</td>\n",
       "      <td>-1.427074</td>\n",
       "      <td>-1.355008</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>-1.142765</td>\n",
       "      <td>0.124791</td>\n",
       "      <td>-1.191008</td>\n",
       "      <td>-1.245891</td>\n",
       "      <td>-0.214618</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>-0.114393</td>\n",
       "      <td>0.592309</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.111207</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>-1.572408</td>\n",
       "      <td>-0.806828</td>\n",
       "      <td>-1.011365</td>\n",
       "      <td>-1.333164</td>\n",
       "      <td>0.176366</td>\n",
       "      <td>-0.925342</td>\n",
       "      <td>-1.726088</td>\n",
       "      <td>-0.697251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.385801 -0.637871  1.776668 -1.224532  0.696430  0.526865  0.732292   \n",
       "1    0.948519 -0.765445  1.253174  0.853284  0.091785  1.172795  1.333181   \n",
       "2    0.523354 -0.519409  0.954034 -1.046433 -0.445678  0.930572  1.006382   \n",
       "3    0.973529 -0.555859  0.168793 -1.076116 -0.714409  0.526865  0.816627   \n",
       "4    0.435820  0.820120  0.056615  0.556453 -0.512860 -0.555068 -1.291756   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "137  0.685917  0.756333  1.327959  1.150115 -0.176946 -1.168702 -1.544762   \n",
       "138 -1.652489 -0.610534  0.954034  1.892192 -0.781592 -0.571216 -0.395693   \n",
       "139  0.673412 -0.492072  1.066212 -0.185624  0.696430  0.123159  0.574163   \n",
       "140 -0.014354  1.011481 -0.055562 -0.334039  0.427699 -1.427074 -1.355008   \n",
       "141 -0.114393  0.592309  0.131400  0.111207  0.293333 -1.572408 -0.806828   \n",
       "\n",
       "            7         8         9        10        11        12  target  \n",
       "0   -0.169549 -0.415783 -0.167467  0.624378  0.252908  0.467725    -1.0  \n",
       "1   -0.590457  1.349742  0.305303  1.067155  0.151048  1.815768    -1.0  \n",
       "2   -0.169549 -0.260002 -0.081509 -0.128343  0.893172  1.516203    -1.0  \n",
       "3   -0.590457  0.363125  0.262324  0.890044  0.427526  1.932265    -1.0  \n",
       "4    0.756449 -0.606183  1.474335 -1.766619 -1.435059 -0.297831     1.0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "137  1.177357 -1.817818 -0.274915 -0.261176 -0.794796 -0.730536     1.0  \n",
       "138  0.335541 -0.450402 -1.027050  1.819877  0.878620 -0.590739    -1.0  \n",
       "139 -0.590457 -0.104220 -0.339384  0.668656  0.383871  1.183353    -1.0  \n",
       "140  0.335541 -1.142765  0.124791 -1.191008 -1.245891 -0.214618     1.0  \n",
       "141 -1.011365 -1.333164  0.176366 -0.925342 -1.726088 -0.697251     1.0  \n",
       "\n",
       "[142 rows x 14 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set kelas 2\n",
    "trainingset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BstlZOwoUN9v"
   },
   "source": [
    "## Pemodelan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "-G-U0kK8T8zK"
   },
   "outputs": [],
   "source": [
    "def training(trainingset, input_neuron=13, hidden_neuron=6, alpha=0.5, max_epoch=1000, verbose=False):\n",
    "    list_kelas = trainingset.keys()\n",
    "    weights = {}\n",
    "\n",
    "    for kelas in list_kelas:\n",
    "        trainset = trainingset[kelas].iloc[:, :-1].values\n",
    "        trainlabel = trainingset[kelas].iloc[:, -1].values\n",
    "        # Train each class using MADALINE\n",
    "        weights[kelas] = train_madaline(\n",
    "            trainset, trainlabel, input_neuron, hidden_neuron, alpha, max_epoch, verbose)\n",
    "    return weights\n",
    "\n",
    "weights = training(trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "z537Gq49Uq6g"
   },
   "outputs": [],
   "source": [
    "weights = training(trainingset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "O4uo083TX55h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.99003823e+02,  1.65424930e+03,  1.94272631e+03,\n",
       "          1.05075140e+02, -2.96138470e+03,  3.38541502e+01],\n",
       "        [-5.31382972e+03, -2.44186955e+02,  5.55795280e+02,\n",
       "          2.18216743e+02,  9.68783815e+01,  1.50979828e+00],\n",
       "        [ 2.65263599e+03,  4.22015957e+03,  2.42449653e+03,\n",
       "          5.05436465e+02, -1.28019971e+03,  7.41435583e+01],\n",
       "        [-3.12471898e+03, -2.00948960e+03,  1.07070022e+03,\n",
       "         -6.81249129e+02, -5.71930376e+03, -1.00815555e+02],\n",
       "        [ 1.23695514e+03, -1.66257741e+04, -2.69550492e+03,\n",
       "          2.85785302e+02,  4.53707248e+03, -3.34509794e+01],\n",
       "        [ 2.89250001e+02, -4.06107940e+03,  2.10293812e+03,\n",
       "          9.79246549e+01, -1.62702248e+03,  4.01850746e+01],\n",
       "        [ 6.62998805e+02, -2.74022237e+03,  3.15279722e+03,\n",
       "          2.44390208e+02, -1.12191211e+03,  5.62577853e+01],\n",
       "        [-2.58582608e+03,  4.20497454e+03, -4.53253830e+03,\n",
       "         -1.82043918e+02,  1.94211100e+03, -3.94183465e-01],\n",
       "        [ 8.18309700e+01, -1.51493006e+04, -2.95687316e+01,\n",
       "         -2.56870137e+02,  6.33892535e+02, -3.41565604e+00],\n",
       "        [ 9.68086738e+02,  7.80062162e+03, -6.22273874e+02,\n",
       "         -1.64638973e+02,  3.64395139e+03,  3.37066607e+01],\n",
       "        [ 1.86469281e+03, -4.28826960e+03,  1.48773955e+03,\n",
       "         -7.01951340e+01, -3.90053542e+03, -2.77414857e+01],\n",
       "        [ 7.86520340e+02, -1.56981640e+03,  3.53899631e+03,\n",
       "          2.83007479e+02, -8.67095832e+02,  3.96735679e+01],\n",
       "        [ 2.52261093e+03,  1.75003491e+03,  1.82498394e+02,\n",
       "          6.59299181e+02,  6.05957172e+03,  4.54436473e+01]]),\n",
       " array([1, 1, 1, 1, 1, 1]),\n",
       " array([-4.64547110e+03, -9.99362524e+03, -3.18255572e+03, -9.37646655e+02,\n",
       "        -6.74740343e+03, -1.09757342e+02,  5.00000000e-01]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm6ORYPJW9L4"
   },
   "source": [
    "## Pengujian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZMEfx_scB-k"
   },
   "source": [
    "Proses testing pada metode one-vs-rest dilakukan dengan memanggil proses testing biner untuk setiap **value** pada dictionary **W**. Kelas pada sebuah data latih adalah **key** pada dictionary **W** yang memiliki nilai prediksi **1**. Lengkapi fungsi **testing_onevsrest** di bawah ini. Output dari fungsi tersebut adalah list nama kelas hasil prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "kJ7jlTTVV_HS"
   },
   "outputs": [],
   "source": [
    "def testing_onevsrest(W, data_uji):\n",
    "    kelas = list(W.keys())\n",
    "    kelas_prediksi = list()\n",
    "\n",
    "    for i in range(data_uji.shape[0]):\n",
    "        # Mencari kelas dengan nilai prediksi tertinggi\n",
    "        y_prediksi = np.argmax([test(*W[k], data_uji[i]) for k in kelas])\n",
    "\n",
    "        # Menambahkan kelas dengan nilai prediksi tertinggi ke hasil\n",
    "        kelas_prediksi.append(kelas[y_prediksi])\n",
    "\n",
    "    return kelas_prediksi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "0Oq4Yi9OW_mP"
   },
   "outputs": [],
   "source": [
    "prediksi_wine = testing_onevsrest(weights, X_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "c94QEubq9Cmw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.93      0.93      0.93        14\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.94      0.95      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(prediksi_wine, y_test_wine, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "swT6Y1X-9Cmx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25cf30a10a0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(prediksi_wine, y_test_wine)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2])\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ruc6SEmqMRKw"
   },
   "source": [
    "# Pertanyaan!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF5WK0xZMUKu"
   },
   "source": [
    "## MADALINE Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Jelaskan bagaimana caranya untuk mengimplementasikan MADALINE yang dapat menerima data multivariable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengimplementasikan MADALINE (Multiple Adaptive Linear Neuron), yang dapat menerima data multivariable, langkah pertama adalah menyiapkan dataset dengan input multivariable yang dinormalisasi. Struktur jaringan terdiri dari lapisan input, lapisan adaptif (ADALINE), dan lapisan output. Setiap neuron di lapisan ADALINE dihitung menggunakan fungsi aktivasi linier. Pelatihan dilakukan dengan algoritma MADALINE Rule II (MR-II), yang memodifikasi bobot secara iteratif untuk meminimalkan kesalahan pada lapisan output. Bobot diperbarui hanya jika perubahan tersebut menurunkan nilai error total. Data multivariable diakomodasi dengan menetapkan jumlah neuron di lapisan input sesuai jumlah fitur, dan hubungan antara lapisan input ke lapisan ADALINE dijembatani melalui bobot yang diinisialisasi secara acak. Validasi dilakukan dengan data terpisah untuk memastikan generalisasi model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cv7UTN7m-nSM"
   },
   "source": [
    "2. Bagaimana caranya untuk mengatur hyperparameternya untuk mencapai akurasi diatas 75%? Jabarkan nilai parameter yang digunakan dan perannya!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mencapai akurasi di atas 75% dalam pelatihan model Madaline, dapat mengatur hyperparameter dengan memilih nilai optimal berdasarkan eksperimen atau grid search seperti yang dilakukan dalam kode di atas. Berikut adalah penjelasan nilai parameter yang digunakan dan perannya:\n",
    "\n",
    "- Hidden Neurons: Jumlah neuron tersembunyi (hidden_neuron) memengaruhi kapasitas model untuk menangkap pola dari data. Nilai yang dipilih seperti 5, 10, dan 15 menentukan kompleksitas jaringan. Terlalu sedikit neuron dapat menyebabkan underfitting, sedangkan terlalu banyak dapat menyebabkan overfitting.\n",
    "\n",
    "- Learning Rate (Alpha): Nilai alpha seperti 0.05, 0.1, dan 0.5 menentukan seberapa besar perubahan bobot dalam setiap iterasi. Nilai yang terlalu besar dapat membuat pelatihan tidak stabil, sedangkan nilai yang terlalu kecil dapat memperlambat konvergensi.\n",
    "\n",
    "- Maximum Epochs: max_epoch seperti 100, 500, dan 1000 mengontrol jumlah iterasi maksimum untuk pelatihan. Semakin besar nilai epoch, semakin banyak peluang model untuk belajar pola dari data, tetapi risiko overfitting juga meningkat jika pelatihan terlalu lama.\n",
    "\n",
    "pada acurasi masih terlihat 73% namun pada grid test menunjukkan 97%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyLRrfczMXXi"
   },
   "source": [
    "## MADALINE Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfeZaJtFAiNz"
   },
   "source": [
    "1. Jelaskan mengapa kita menggunakan metode One-vs-Rest untuk klasifikasi multi-kelas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metode One-vs-Rest (OvR) digunakan dalam klasifikasi multi-kelas untuk menyederhanakan masalah menjadi serangkaian klasifikasi biner. Setiap kelas diperlakukan secara independen dengan membandingkan satu kelas tertentu (positif) dengan semua kelas lainnya (negatif). Pendekatan ini memungkinkan penggunaan algoritma klasifikasi biner yang sederhana dan efektif, seperti SVM atau Logistic Regression, pada masalah multi-kelas yang kompleks. Selain itu, OvR fleksibel terhadap dataset dengan distribusi yang tidak seimbang dan sering lebih efisien secara komputasi dibanding pendekatan lain seperti One-vs-One. Namun, prediksi akhir ditentukan berdasarkan skor atau probabilitas tertinggi dari setiap model biner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bagaimana caranya untuk mengatur hyperparameternya untuk mencapai akurasi diatas 90%? Jabarkan nilai hyperparameter yang digunakan dan perannya!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada proses di atas telah dilakukan proses tuning secara manual dimana saya memasukkan nilai hyperparameter yang berbeda-beda untuk mendapatkan akurasi yang lebih tinggi. Berikut adalah penjelasan nilai hyperparameter yang digunakan dan perannya:\n",
    "\n",
    "- Hidden Neurons: Jumlah neuron tersembunyi (hidden_neuron) memengaruhi kapasitas model untuk menangkap pola dari data. Nilai yang dipilih seperti 5, 10, dan 15 menentukan kompleksitas jaringan. Terlalu sedikit neuron dapat menyebabkan underfitting, sedangkan terlalu banyak dapat menyebabkan overfitting.\n",
    "\n",
    "- Learning Rate (Alpha): Nilai alpha seperti 0.05, 0.1, dan 0.5 menentukan seberapa besar perubahan bobot dalam setiap iterasi. Nilai yang terlalu besar dapat membuat pelatihan tidak stabil, sedangkan nilai yang terlalu kecil dapat memperlambat konvergensi.\n",
    "\n",
    "- Maximum Epochs: max_epoch seperti 100, 500, dan 1000 mengontrol jumlah iterasi maksimum untuk pelatihan. Semakin besar nilai epoch, semakin banyak peluang model untuk belajar pola dari data, tetapi risiko overfitting juga meningkat jika pelatihan terlalu lama.\n",
    "\n",
    "- Input Neurons : Jumlah neuron input (input_neuron) menentukan dimensi data masukan. Nilai yang dipilih harus sesuai dengan jumlah fitur pada dataset. Jumlah neuron input yang salah dapat menyebabkan kesalahan dalam representasi data.\n",
    "\n",
    "Pada data di atas didapatkan akuasi 93%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
