{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Madaline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aktivasi(x):\n",
    "  if x < 0:\n",
    "    return -1\n",
    "  else:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mr1(train_data, train_target, alpha=0.1, max_epoch=10):\n",
    "    w = np.random.random((2, 2))  # Inisialisasi bobot acak untuk lapisan tersembunyi\n",
    "    v = np.array([0.5, 0.5])  # Bobot tetap untuk lapisan output\n",
    "    b = np.random.random(2)  # Inisialisasi bias acak untuk lapisan tersembunyi\n",
    "    b = np.append(b, 0.5)  # Menambahkan bias untuk neuron output\n",
    "    epoch = 0\n",
    "    v_aktivasi = np.vectorize(aktivasi)  # Vektorisasi fungsi aktivasi\n",
    "    weight_updated = True  # Flag untuk melacak apakah bobot diperbarui\n",
    "\n",
    "    while weight_updated == True and epoch < max_epoch:  # Loop pelatihan hingga bobot tidak diperbarui atau mencapai epoch maksimal\n",
    "        weight_updated = False\n",
    "        for data, target in zip(train_data, train_target):  # Loop melalui setiap data dan targetnya\n",
    "            z_in = np.dot(data, w)  # Menghitung input untuk lapisan tersembunyi\n",
    "            z_in = z_in + b[:-1]  # Menambahkan bias ke input lapisan tersembunyi\n",
    "            z = v_aktivasi(z_in)  # Mengaplikasikan fungsi aktivasi ke output lapisan tersembunyi\n",
    "            y_in = np.dot(z, v) + b[-1]  # Menghitung input untuk lapisan output\n",
    "            y = v_aktivasi(y_in)  # Mengaplikasikan fungsi aktivasi ke output lapisan output\n",
    "\n",
    "            # Jika output tidak sesuai dengan target, perbarui bobot dan bias\n",
    "            if y != target:\n",
    "                weight_updated = True\n",
    "                if target == 1:\n",
    "                    index = np.argmin(np.abs(z_in))  # Cari indeks neuron yang memiliki nilai terkecil\n",
    "                    b[index] = b[index] + alpha * (1 - z_in[index])  # Perbarui bias untuk neuron tersebut\n",
    "                    w[:, index] = w[:, index] + alpha * (1 - z_in[index]) * data  # Perbarui bobot untuk neuron tersebut\n",
    "                elif target == -1:\n",
    "                    index = np.where(z_in > 0)[0]  # Temukan indeks neuron dengan nilai positif\n",
    "\n",
    "                    if len(index) == 1:\n",
    "                        index = index[0]\n",
    "                        b[index] = b[index] + alpha * (-1 - z_in[index])  # Perbarui bias\n",
    "                        w[:, index] = w[:, index] + alpha * (-1 - z_in[index]) * data  # Perbarui bobot\n",
    "        \n",
    "        epoch = epoch + 1  # Naikkan hitungan epoch\n",
    "\n",
    "    return (w, v, b)  # Kembalikan bobot dan bias yang telah diperbarui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inisialisasi:\n",
    "    w: Matriks bobot dengan ukuran 2x2 yang diinisialisasi secara acak untuk lapisan tersembunyi.\n",
    "    v: Array bobot untuk lapisan output, dengan nilai tetap [0.5, 0.5].\n",
    "    b: Vektor bias untuk setiap neuron di lapisan tersembunyi dan output, dengan nilai acak.\n",
    "\n",
    "Proses Pelatihan:\n",
    "- Loop utama (while) berlanjut hingga bobot tidak lagi diperbarui atau jumlah epoch mencapai max_epoch.\n",
    "- Untuk setiap pasangan data dan target, dilakukan langkah-langkah berikut:\n",
    "- Menghitung nilai z_in sebagai input ke lapisan tersembunyi, kemudian menerapkan fungsi aktivasi untuk mendapatkan output (z).\n",
    "- Menghitung nilai y_in untuk lapisan output menggunakan z, kemudian menerapkan fungsi aktivasi untuk mendapatkan output akhir (y).\n",
    "\n",
    "Update Bobot dan Bias:\n",
    "- Jika output (y) tidak sama dengan target, dilakukan pembaruan bobot dan bias:\n",
    "- Jika target adalah 1, bobot dan bias dari neuron dengan nilai terkecil diperbarui.\n",
    "- Jika target adalah -1, hanya neuron dengan nilai positif yang diperbarui.\n",
    "\n",
    "Penghentian:\n",
    "- Pelatihan dihentikan ketika semua bobot telah diperbarui dengan benar atau telah mencapai batas epoch yang ditentukan.\n",
    "\n",
    "Fungsi Utama\n",
    "\n",
    "- Aktivasi: Fungsi aktivasi adalah fungsi langkah yang mengubah input menjadi 1 atau -1, tergantung pada apakah input lebih besar atau lebih kecil dari nol.\n",
    "- Pembaruan Bobot: Pembaruan bobot dilakukan menggunakan aturan belajar MR1, yang langsung memperbarui bobot jika ada kesalahan dalam klasifikasi.\n",
    "\n",
    "Kesimpulan\n",
    "\n",
    "Kode ini mengimplementasikan Madaline Rule 1, yang merupakan pendekatan sederhana dalam melatih jaringan Madaline dengan memperbarui bobot secara lokal berdasarkan perbedaan antara output dan target. Pendekatan ini bekerja dengan mengoreksi neuron satu per satu dan memastikan bahwa kesalahan dikurangi secepat mungkin tanpa menghitung perubahan bobot secara menyeluruh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mr2(train_data, train_target, alpha=0.1, max_epoch=10):\n",
    "    # Inisialisasi bobot dan bias\n",
    "    w = np.random.random((2, 2))  # Matriks bobot acak untuk lapisan tersembunyi\n",
    "    v = np.array([0.5, 0.5])  # Bobot tetap untuk lapisan output\n",
    "    b = np.random.random(2)  # Bias acak untuk lapisan tersembunyi\n",
    "    b = np.append(b, 0.5)  # Tambahkan bias untuk neuron output\n",
    "    epoch = 0\n",
    "    v_aktivasi = np.vectorize(aktivasi)  # Vektorisasi fungsi aktivasi\n",
    "    weight_updated = True  # Flag untuk melacak apakah ada pembaruan bobot\n",
    "\n",
    "    while weight_updated == True and epoch < max_epoch:  # Loop pelatihan\n",
    "        weight_updated = False\n",
    "        for data, target in zip(train_data, train_target):  # Loop untuk setiap data pelatihan\n",
    "            z_in = np.dot(data, w)  # Hitung input untuk lapisan tersembunyi\n",
    "            z_in = z_in + b[:-1]  # Tambahkan bias ke input lapisan tersembunyi\n",
    "            z = v_aktivasi(z_in)  # Aplikasikan fungsi aktivasi ke output lapisan tersembunyi\n",
    "            y_in = np.dot(z, v) + b[-1]  # Hitung input untuk lapisan output\n",
    "            y = v_aktivasi(y_in)  # Aplikasikan fungsi aktivasi ke output lapisan output\n",
    "\n",
    "            # Jika output tidak sesuai dengan target, perbarui bobot dan bias\n",
    "            if y != target:\n",
    "                weight_updated = True\n",
    "\n",
    "                # MR2: Hitung perubahan minimal pada bobot dan bias\n",
    "                minimal_changes = []\n",
    "                for i in range(len(z_in)):\n",
    "                    if target == 1 and z_in[i] < 0:\n",
    "                        change = alpha * (1 - z_in[i])  # Hitung perubahan jika target positif\n",
    "                        minimal_changes.append((change, i))\n",
    "                    elif target == -1 and z_in[i] > 0:\n",
    "                        change = alpha * (-1 - z_in[i])  # Hitung perubahan jika target negatif\n",
    "                        minimal_changes.append((change, i))\n",
    "\n",
    "                if minimal_changes:\n",
    "                    # Pilih perubahan dengan dampak minimal\n",
    "                    min_change, min_index = min(minimal_changes, key=lambda x: abs(x[0]))\n",
    "                    b[min_index] += min_change  # Perbarui bias dengan perubahan minimal\n",
    "                    w[:, min_index] += min_change * data  # Perbarui bobot dengan perubahan minimal\n",
    "\n",
    "        epoch += 1  # Naikkan hitungan epoch\n",
    "\n",
    "    return (w, v, b)  # Kembalikan bobot dan bias yang telah diperbarui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini mengimplementasikan algoritma Madaline Rule 2 (MR2) dengan penekanan pada perhitungan perubahan bobot dan bias secara minimal untuk memperbaiki kesalahan klasifikasi.\n",
    "1. Inisialisasi\n",
    "\n",
    "    w: Matriks bobot untuk lapisan tersembunyi, diinisialisasi dengan nilai acak.\n",
    "    v: Bobot tetap untuk lapisan output, dengan nilai awal [0.5, 0.5].\n",
    "    b: Vektor bias untuk lapisan tersembunyi, yang kemudian ditambahkan dengan bias tambahan untuk neuron output.\n",
    "\n",
    "2. Proses Pelatihan\n",
    "\n",
    "    Loop utama (while) berlanjut selama bobot masih diperbarui atau hingga batas epoch tercapai.\n",
    "    Untuk setiap data dalam dataset pelatihan, hitung input dan output untuk lapisan tersembunyi dan output menggunakan fungsi aktivasi.\n",
    "\n",
    "3. Pembaruan Bobot dan Bias (MR2)\n",
    "\n",
    "    Jika output dari jaringan (y) tidak sesuai dengan target, kita perlu memperbarui bobot dan bias.\n",
    "\n",
    "    Untuk setiap neuron dalam lapisan tersembunyi, dihitung perubahan yang diperlukan untuk memperbaiki kesalahan berdasarkan target:\n",
    "        Jika targetnya 1 dan input untuk neuron tersebut (z_in[i]) negatif, maka perubahan dihitung sebagai alpha * (1 - z_in[i]).\n",
    "        Jika targetnya -1 dan input neuron positif, perubahan dihitung sebagai alpha * (-1 - z_in[i]).\n",
    "\n",
    "    Minimal Changes Calculation: Kode ini mengumpulkan semua perubahan yang mungkin untuk setiap neuron dan memilih perubahan dengan dampak terkecil untuk memperbarui bobot dan bias. Pemilihan perubahan ini dilakukan dengan menggunakan fungsi min, yang mencari perubahan dengan nilai absolut terkecil.\n",
    "\n",
    "4. Kesimpulan\n",
    "\n",
    "    Perbedaan dengan MR1: MR2 lebih hati-hati dalam memperbarui bobot dan bias karena memilih perubahan yang memiliki dampak minimal, dibandingkan dengan MR1 yang memperbarui bobot secara langsung.\n",
    "    Pendekatan ini membantu mengurangi kesalahan secara bertahap tanpa mempengaruhi stabilitas jaringan secara drastis, namun membutuhkan lebih banyak perhitungan untuk menemukan perubahan yang paling kecil.\n",
    "\n",
    "Kelebihan MR2\n",
    "\n",
    "- Efisiensi dalam Perbaikan Kesalahan: MR2 mencoba memperbaiki kesalahan dengan cara yang paling minimal, mengurangi kemungkinan perubahan besar yang dapat merusak jaringan.\n",
    "- Akurasi Lebih Tinggi: Dengan mencari perubahan terkecil, MR2 cenderung menghasilkan hasil klasifikasi yang lebih stabil dan akurat dalam jangka panjang.\n",
    "\n",
    "Kekurangan MR2\n",
    "\n",
    "- Kompleksitas Komputasi: Perhitungan untuk menemukan perubahan minimal dapat menjadi mahal secara komputasi, terutama jika ada banyak neuron dalam jaringan.\n",
    "\n",
    "Pendekatan ini memberikan metode yang lebih terkontrol dan stabil untuk memperbaiki kesalahan klasifikasi dibandingkan dengan Madaline Rule 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mr3(train_data, train_target, alpha=0.1, max_epoch=10):\n",
    "    # Inisialisasi bobot dan bias\n",
    "    w = np.random.random((2, 2))  # Matriks bobot untuk lapisan tersembunyi\n",
    "    v = np.array([0.5, 0.5])  # Bobot tetap untuk lapisan output\n",
    "    b = np.random.random(2)  # Bias acak untuk lapisan tersembunyi\n",
    "    b = np.append(b, 0.5)  # Tambahkan bias untuk neuron output\n",
    "    epoch = 0\n",
    "    v_aktivasi = np.vectorize(aktivasi)  # Vektorisasi fungsi aktivasi\n",
    "    weight_updated = True  # Flag untuk melacak apakah ada pembaruan bobot\n",
    "\n",
    "    while weight_updated and epoch < max_epoch:  # Loop pelatihan\n",
    "        weight_updated = False\n",
    "        for data, target in zip(train_data, train_target):  # Loop untuk setiap data pelatihan\n",
    "            z_in = np.dot(data, w)  # Hitung input untuk lapisan tersembunyi\n",
    "            z_in = z_in + b[:-1]  # Tambahkan bias ke input lapisan tersembunyi\n",
    "            z = v_aktivasi(z_in)  # Aplikasikan fungsi aktivasi ke output lapisan tersembunyi\n",
    "            y_in = np.dot(z, v) + b[-1]  # Hitung input untuk lapisan output\n",
    "            y = v_aktivasi(y_in)  # Aplikasikan fungsi aktivasi ke output lapisan output\n",
    "\n",
    "            # Jika output tidak sesuai dengan target, perbarui bobot dan bias\n",
    "            if y != target:\n",
    "                weight_updated = True\n",
    "\n",
    "                # MR3: Penyesuaian bobot secara bertahap\n",
    "                for i in range(len(z_in)):\n",
    "                    if target == 1 and z_in[i] < 0:\n",
    "                        change = alpha * (1 - z_in[i]) * 0.5  # Perubahan yang lebih kecil secara bertahap\n",
    "                        b[i] += change  # Perbarui bias\n",
    "                        w[:, i] += change * data  # Perbarui bobot\n",
    "                    elif target == -1 and z_in[i] > 0:\n",
    "                        change = alpha * (-1 - z_in[i]) * 0.5  # Perubahan yang lebih kecil secara bertahap\n",
    "                        b[i] += change  # Perbarui bias\n",
    "                        w[:, i] += change * data  # Perbarui bobot\n",
    "\n",
    "        epoch += 1  # Naikkan hitungan epoch\n",
    "\n",
    "    return (w, v, b)  # Kembalikan bobot dan bias yang telah diperbarui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode ini mengimplementasikan Madaline Rule 3 (MR3) yang menggunakan pendekatan penyesuaian bertahap untuk memperbarui bobot dan bias jaringan. Madaline Rule 3 mencoba memperbaiki kesalahan klasifikasi secara bertahap dengan mengurangi dampak perubahan yang besar.\n",
    "1. Inisialisasi\n",
    "\n",
    "    w: Matriks bobot untuk lapisan tersembunyi, diinisialisasi dengan nilai acak.\n",
    "    v: Bobot tetap untuk lapisan output, diinisialisasi dengan nilai [0.5, 0.5].\n",
    "    b: Vektor bias untuk lapisan tersembunyi dan output, diinisialisasi dengan nilai acak.\n",
    "\n",
    "2. Proses Pelatihan\n",
    "\n",
    "    Loop utama berjalan selama pembaruan bobot terjadi atau hingga batas maksimal epoch tercapai.\n",
    "    Untuk setiap data pelatihan, input dan output dihitung menggunakan fungsi aktivasi untuk lapisan tersembunyi dan lapisan output.\n",
    "\n",
    "3. Penyesuaian Bobot dan Bias (MR3)\n",
    "\n",
    "    Jika output jaringan (y) tidak sesuai dengan target, proses pembaruan bobot dan bias dimulai.\n",
    "\n",
    "    Penyesuaian bertahap: Pada MR3, perubahan bobot dan bias dilakukan secara bertahap dengan mengalikan perubahan dengan 0.5. Tujuan dari ini adalah untuk membuat perubahan lebih kecil dan lebih terkontrol.\n",
    "        Jika targetnya 1 dan input untuk neuron tertentu (z_in[i]) kurang dari nol, maka perubahan dihitung sebagai alpha * (1 - z_in[i]) * 0.5.\n",
    "        Jika targetnya -1 dan input neuron tersebut positif, perubahan dihitung sebagai alpha * (-1 - z_in[i]) * 0.5.\n",
    "\n",
    "    Proses penyesuaian yang bertahap ini dilakukan untuk mengurangi risiko overshooting atau perubahan drastis dalam bobot yang dapat mempengaruhi stabilitas jaringan.\n",
    "\n",
    "4. Kesimpulan\n",
    "\n",
    "Perbedaan dengan MR1 dan MR2:\n",
    "-   MR1 memperbarui bobot langsung berdasarkan kesalahan yang terjadi.\n",
    "-   MR2 memilih perubahan dengan dampak minimal.\n",
    "-   MR3 melakukan penyesuaian bertahap untuk mengontrol besar perubahan pada bobot dan bias, sehingga mengurangi dampak perubahan yang terlalu besar.\n",
    "\n",
    "Kelebihan MR3\n",
    "\n",
    "-   Stabilitas Jaringan: Dengan melakukan perubahan secara bertahap, MR3 meningkatkan stabilitas jaringan dan mengurangi kemungkinan perubahan besar yang dapat merusak pelatihan.\n",
    "-   Kontrol yang Lebih Baik: Membuat pembelajaran lebih halus dan terkendali dibandingkan dengan pendekatan langsung dari MR1 atau perubahan minimal MR2.\n",
    "\n",
    "Kekurangan MR3\n",
    "\n",
    "-   Waktu Pelatihan Lebih Lama: Karena perubahan dilakukan dalam jumlah yang lebih kecil, MR3 mungkin membutuhkan lebih banyak epoch untuk mencapai konvergensi.\n",
    "-   Kompleksitas Komputasi: Meskipun stabil, proses ini dapat menjadi lebih lambat dibandingkan dengan MR1 atau MR2 karena penyesuaian yang lebih halus.\n",
    "\n",
    "Pendekatan MR3 ini berfokus pada memperbaiki kesalahan secara bertahap untuk meningkatkan akurasi dan stabilitas dalam jangka panjang selama pelatihan jaringan Madaline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(w,v,b,test_data):\n",
    "  v_aktivasi = np.vectorize(aktivasi)\n",
    "  z_in = np.dot(test_data, w)\n",
    "  z_in = z_in + b[:-1]\n",
    "  z = v_aktivasi(z_in)\n",
    "  y_in = np.dot(z, v) + b[-1]\n",
    "  y = v_aktivasi(y_in)\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(a, b):\n",
    "  s = [1 if a[i] == b[i] else 0 for i in range(len(a))]\n",
    "  return sum(s) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ 1 -1  1 -1]\n",
      "Target: [ 1 -1 -1 -1]\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,1],[1,-1],[-1,1],[-1,-1]])\n",
    "target = np.array([1,-1,-1,-1])\n",
    "(w,v,b) = train_mr1(data,target,alpha=0.8,max_epoch=10)\n",
    "output = test(w,v,b,data)\n",
    "accuracy = calc_accuracy(output, target)\n",
    "print('Output:', output)\n",
    "print('Target:', target)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ 1 -1 -1 -1]\n",
      "Target: [ 1 -1 -1 -1]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,1],[1,-1],[-1,1],[-1,-1]])\n",
    "target = np.array([1,-1,-1,-1])\n",
    "(w,v,b) = train_mr2(data,target,alpha=0.8,max_epoch=10)\n",
    "output = test(w,v,b,data)\n",
    "accuracy = calc_accuracy(output, target)\n",
    "print('Output:', output)\n",
    "print('Target:', target)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [ 1 -1 -1 -1]\n",
      "Target: [ 1 -1 -1 -1]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1,1],[1,-1],[-1,1],[-1,-1]])\n",
    "target = np.array([1,-1,-1,-1])\n",
    "(w,v,b) = train_mr3(data,target,alpha=0.8,max_epoch=10)\n",
    "output = test(w,v,b,data)\n",
    "accuracy = calc_accuracy(output, target)\n",
    "print('Output:', output)\n",
    "print('Target:', target)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
